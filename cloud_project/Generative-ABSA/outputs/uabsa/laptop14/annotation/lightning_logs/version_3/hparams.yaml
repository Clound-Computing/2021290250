adam_epsilon: 1.0e-08
dataset: laptop14
do_direct_eval: false
do_eval: false
do_train: true
eval_batch_size: 16
gradient_accumulation_steps: 1
learning_rate: 0.0003
max_seq_length: 128
model_name_or_path: t5-base
n_gpu: 0
num_train_epochs: 20
output_dir: ./outputs/uabsa/laptop14/annotation
paradigm: annotation
seed: 42
task: uabsa
train_batch_size: 16
warmup_steps: 0.0
weight_decay: 0.0
